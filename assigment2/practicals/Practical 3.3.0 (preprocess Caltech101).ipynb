{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script loads the Caltech101 dataset (stored as JPEG images in subfolders), and then uses a pre-trained VGG16 network to obtain neural code features (from the fc2 layer) for each images (see fc2_VGG16.ipynb for more explanation). Those features are stored in pickle files, along with the corresponding class.\n",
    "\n",
    "The dataset consists of images divided into 101 classes, as well as an extra background/clutter class with random images. We will save one pickle file for all 101 classes, and another for the background set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jorge/.local/share/virtualenvs/RecommenderSystems-c5N1t04d/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# load pre-trained VGG16 from Keras\n",
    "base_model = VGG16(weights=\"imagenet\")\n",
    "fc2_model = Model(inputs=base_model.input, outputs=base_model.get_layer(\"fc2\").output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: data/caltech101/classes\n",
      "Feature size 4096\n",
      "Data fc2 shape (8677, 4096)\n",
      "Data labels: \n",
      "loading class 0: dalmatian\n",
      "loading class 1: cup\n",
      "loading class 2: elephant\n",
      "loading class 3: snoopy\n",
      "loading class 4: cannon\n",
      "loading class 5: beaver\n",
      "loading class 6: garfield\n",
      "loading class 7: crab\n",
      "loading class 8: tick\n",
      "loading class 9: sea_horse\n",
      "loading class 10: crocodile\n",
      "loading class 11: gerenuk\n",
      "loading class 12: brain\n",
      "loading class 13: chandelier\n",
      "loading class 14: chair\n",
      "loading class 15: bonsai\n",
      "loading class 16: soccer_ball\n",
      "loading class 17: platypus\n",
      "loading class 18: butterfly\n",
      "loading class 19: bass\n",
      "loading class 20: electric_guitar\n",
      "loading class 21: pizza\n",
      "loading class 22: rooster\n",
      "loading class 23: flamingo_head\n",
      "loading class 24: stegosaurus\n",
      "loading class 25: emu\n",
      "loading class 26: watch\n",
      "loading class 27: rhino\n",
      "loading class 28: Leopards\n",
      "loading class 29: gramophone\n",
      "loading class 30: trilobite\n",
      "loading class 31: ibis\n",
      "loading class 32: Faces\n",
      "loading class 33: car_side\n",
      "loading class 34: llama\n",
      "loading class 35: inline_skate\n",
      "loading class 36: revolver\n",
      "loading class 37: scissors\n",
      "loading class 38: mayfly\n",
      "loading class 39: dolphin\n",
      "loading class 40: Faces_easy\n",
      "loading class 41: umbrella\n",
      "loading class 42: ceiling_fan\n",
      "loading class 43: starfish\n",
      "loading class 44: sunflower\n",
      "loading class 45: octopus\n",
      "loading class 46: ewer\n",
      "loading class 47: nautilus\n",
      "loading class 48: okapi\n",
      "loading class 49: hedgehog\n",
      "loading class 50: binocular\n",
      "loading class 51: ketch\n",
      "loading class 52: pigeon\n",
      "loading class 53: hawksbill\n",
      "loading class 54: scorpion\n",
      "loading class 55: pyramid\n",
      "loading class 56: water_lilly\n",
      "loading class 57: mandolin\n",
      "loading class 58: lamp\n",
      "loading class 59: lotus\n",
      "loading class 60: pagoda\n",
      "loading class 61: ferry\n",
      "loading class 62: stop_sign\n",
      "loading class 63: windsor_chair\n",
      "loading class 64: camera\n",
      "loading class 65: schooner\n",
      "loading class 66: minaret\n",
      "loading class 67: stapler\n",
      "loading class 68: wrench\n",
      "loading class 69: laptop\n",
      "loading class 70: menorah\n",
      "loading class 71: headphone\n",
      "loading class 72: wild_cat\n",
      "loading class 73: yin_yang\n",
      "loading class 74: anchor\n",
      "loading class 75: buddha\n",
      "loading class 76: grand_piano\n",
      "loading class 77: helicopter\n",
      "loading class 78: joshua_tree\n",
      "loading class 79: cellphone\n",
      "loading class 80: saxophone\n",
      "loading class 81: cougar_face\n",
      "loading class 82: lobster\n",
      "loading class 83: brontosaurus\n",
      "loading class 84: crocodile_head\n",
      "loading class 85: dragonfly\n",
      "loading class 86: ant\n",
      "loading class 87: panda\n",
      "loading class 88: airplanes\n",
      "loading class 89: metronome\n",
      "loading class 90: wheelchair\n",
      "loading class 91: crayfish\n",
      "loading class 92: strawberry\n",
      "loading class 93: accordion\n",
      "loading class 94: kangaroo\n",
      "loading class 95: cougar_body\n",
      "loading class 96: dollar_bill\n",
      "loading class 97: euphonium\n",
      "loading class 98: Motorbikes\n",
      "loading class 99: barrel\n",
      "loading class 100: flamingo\n"
     ]
    }
   ],
   "source": [
    "# obtain Caltech101 filepaths, classes, and labels. Convert images to fc2 neural codes\n",
    "path = os.path.join(\"data\", \"caltech101\", \"classes\")\n",
    "print(\"Path: \" + str(path))\n",
    "#print(path)\n",
    "\n",
    "\n",
    "data_paths = [filepath for filepath in glob.glob(os.path.join(path, \"**\"), recursive=True) if filepath.lower().endswith(\".jpg\")]\n",
    "print(data_paths)\n",
    "\n",
    "feature_size = int(fc2_model.output.shape[1])  # = 4096 for the fc2-layer of VGG16\n",
    "print(\"Feature size {}\".format(feature_size))\n",
    "\n",
    "data_classes = os.listdir(path)\n",
    "print(\"Data classes: \")# + str(data_classes))\n",
    "\n",
    "n_examples = len(data_paths)\n",
    "data_fc2 = np.empty((n_examples, feature_size))\n",
    "print(\"Data fc2 shape {}\".format(data_fc2.shape))\n",
    "\n",
    "data_labels = np.empty(n_examples, dtype=int)\n",
    "print(\"Data labels: \")\n",
    "#print(data_labels)\n",
    "\n",
    "i = 0\n",
    "for y, c in enumerate(data_classes):\n",
    "    print(\"loading class {}: {}\".format(y, c))\n",
    "    class_path = os.path.join(path, c)\n",
    "    for filename in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, filename)\n",
    "        img = image.load_img(image_path, target_size=(224, 224))\n",
    "        array = image.img_to_array(img)\n",
    "        x = np.expand_dims(array, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        fc2 = fc2_model.predict(x)\n",
    "        data_fc2[i] = fc2\n",
    "        data_labels[i] = y\n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the Caltech101 \"BACKGROUND_Google\" filepaths and fc2 neural codes.\n",
    "bg_path = os.path.join(\"data\", \"caltech101\", \"BACKGROUND_Google\")\n",
    "bg_data_paths = [os.path.join(bg_path, filepath) for filepath in os.listdir(bg_path)]\n",
    "n_bg_examples = len(bg_data_paths)\n",
    "bg_data_fc2 = np.empty((n_bg_examples, feature_size))\n",
    "for i, image_path in enumerate(bg_data_paths):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    array = image.img_to_array(img)\n",
    "    x = np.expand_dims(array, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    fc2 = fc2_model.predict(x)\n",
    "    bg_data_fc2[i] = fc2\n",
    "\n",
    "# save neural codes, labels, paths, and list of classes to pickle file\n",
    "with open(os.path.join(\"data\",\"caltech101_VGG16_fc2.p\"), \"wb\") as f:\n",
    "    pickle.dump((data_fc2, data_labels, data_paths, data_classes), f)\n",
    "\n",
    "# save neural codes & paths of BACKGROUND_Google class to pickle file\n",
    "with open(os.path.join(\"data\",\"caltech101_VGG16_fc2_bg.p\"), \"wb\") as f:\n",
    "    pickle.dump((bg_data_fc2, bg_data_paths), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained VGG16 from Keras\n",
    "base_model = VGG16(weights=\"imagenet\")\n",
    "fc1_model = Model(inputs=base_model.input, outputs=base_model.get_layer(\"fc1\").output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path: data/caltech101/classes\n",
      "Feature size 4096\n",
      "Data classes: \n",
      "Data fc1 shape (8677, 4096)\n",
      "Data labels: \n",
      "loading class 0: dalmatian\n",
      "loading class 1: cup\n",
      "loading class 2: elephant\n",
      "loading class 3: snoopy\n",
      "loading class 4: cannon\n",
      "loading class 5: beaver\n",
      "loading class 6: garfield\n",
      "loading class 7: crab\n",
      "loading class 8: tick\n",
      "loading class 9: sea_horse\n",
      "loading class 10: crocodile\n",
      "loading class 11: gerenuk\n",
      "loading class 12: brain\n",
      "loading class 13: chandelier\n",
      "loading class 14: chair\n",
      "loading class 15: bonsai\n",
      "loading class 16: soccer_ball\n",
      "loading class 17: platypus\n",
      "loading class 18: butterfly\n",
      "loading class 19: bass\n",
      "loading class 20: electric_guitar\n",
      "loading class 21: pizza\n",
      "loading class 22: rooster\n",
      "loading class 23: flamingo_head\n",
      "loading class 24: stegosaurus\n",
      "loading class 25: emu\n",
      "loading class 26: watch\n",
      "loading class 27: rhino\n",
      "loading class 28: Leopards\n",
      "loading class 29: gramophone\n",
      "loading class 30: trilobite\n",
      "loading class 31: ibis\n",
      "loading class 32: Faces\n",
      "loading class 33: car_side\n",
      "loading class 34: llama\n",
      "loading class 35: inline_skate\n",
      "loading class 36: revolver\n",
      "loading class 37: scissors\n",
      "loading class 38: mayfly\n",
      "loading class 39: dolphin\n",
      "loading class 40: Faces_easy\n",
      "loading class 41: umbrella\n",
      "loading class 42: ceiling_fan\n",
      "loading class 43: starfish\n",
      "loading class 44: sunflower\n",
      "loading class 45: octopus\n",
      "loading class 46: ewer\n",
      "loading class 47: nautilus\n",
      "loading class 48: okapi\n",
      "loading class 49: hedgehog\n",
      "loading class 50: binocular\n",
      "loading class 51: ketch\n",
      "loading class 52: pigeon\n",
      "loading class 53: hawksbill\n",
      "loading class 54: scorpion\n",
      "loading class 55: pyramid\n",
      "loading class 56: water_lilly\n",
      "loading class 57: mandolin\n",
      "loading class 58: lamp\n",
      "loading class 59: lotus\n",
      "loading class 60: pagoda\n",
      "loading class 61: ferry\n",
      "loading class 62: stop_sign\n",
      "loading class 63: windsor_chair\n",
      "loading class 64: camera\n",
      "loading class 65: schooner\n",
      "loading class 66: minaret\n",
      "loading class 67: stapler\n",
      "loading class 68: wrench\n",
      "loading class 69: laptop\n",
      "loading class 70: menorah\n",
      "loading class 71: headphone\n",
      "loading class 72: wild_cat\n",
      "loading class 73: yin_yang\n",
      "loading class 74: anchor\n",
      "loading class 75: buddha\n",
      "loading class 76: grand_piano\n",
      "loading class 77: helicopter\n",
      "loading class 78: joshua_tree\n",
      "loading class 79: cellphone\n",
      "loading class 80: saxophone\n",
      "loading class 81: cougar_face\n",
      "loading class 82: lobster\n",
      "loading class 83: brontosaurus\n",
      "loading class 84: crocodile_head\n",
      "loading class 85: dragonfly\n",
      "loading class 86: ant\n",
      "loading class 87: panda\n",
      "loading class 88: airplanes\n",
      "loading class 89: metronome\n",
      "loading class 90: wheelchair\n",
      "loading class 91: crayfish\n",
      "loading class 92: strawberry\n",
      "loading class 93: accordion\n",
      "loading class 94: kangaroo\n",
      "loading class 95: cougar_body\n",
      "loading class 96: dollar_bill\n",
      "loading class 97: euphonium\n",
      "loading class 98: Motorbikes\n",
      "loading class 99: barrel\n",
      "loading class 100: flamingo\n"
     ]
    }
   ],
   "source": [
    "# obtain Caltech101 filepaths, classes, and labels. Convert images to fc2 neural codes\n",
    "path = os.path.join(\"data\", \"caltech101\", \"classes\")\n",
    "print(\"Path: \" + str(path))\n",
    "#print(path)\n",
    "\n",
    "\n",
    "data_paths = [filepath for filepath in glob.glob(os.path.join(path, \"**\"), recursive=True) if filepath.lower().endswith(\".jpg\")]\n",
    "#print(data_paths)\n",
    "\n",
    "feature_size = int(fc1_model.output.shape[1])  # = 4096 for the fc2-layer of VGG16\n",
    "print(\"Feature size {}\".format(feature_size))\n",
    "\n",
    "data_classes = os.listdir(path)\n",
    "print(\"Data classes: \")# + str(data_classes))\n",
    "\n",
    "n_examples = len(data_paths)\n",
    "data_fc1 = np.empty((n_examples, feature_size))\n",
    "print(\"Data fc1 shape {}\".format(data_fc1.shape))\n",
    "\n",
    "data_labels = np.empty(n_examples, dtype=int)\n",
    "print(\"Data labels: \")\n",
    "#print(data_labels)\n",
    "\n",
    "i = 0\n",
    "for y, c in enumerate(data_classes):\n",
    "    print(\"loading class {}: {}\".format(y, c))\n",
    "    class_path = os.path.join(path, c)\n",
    "    for filename in os.listdir(class_path):\n",
    "        image_path = os.path.join(class_path, filename)\n",
    "        img = image.load_img(image_path, target_size=(224, 224))\n",
    "        array = image.img_to_array(img)\n",
    "        x = np.expand_dims(array, axis=0)\n",
    "        x = preprocess_input(x)\n",
    "        fc1 = fc1_model.predict(x)\n",
    "        data_fc1[i] = fc1\n",
    "        data_labels[i] = y\n",
    "        i += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# obtain the Caltech101 \"BACKGROUND_Google\" filepaths and fc2 neural codes.\n",
    "bg_path = os.path.join(\"data\", \"caltech101\", \"BACKGROUND_Google\")\n",
    "bg_data_paths = [os.path.join(bg_path, filepath) for filepath in os.listdir(bg_path)]\n",
    "n_bg_examples = len(bg_data_paths)\n",
    "bg_data_fc1 = np.empty((n_bg_examples, feature_size))\n",
    "for i, image_path in enumerate(bg_data_paths):\n",
    "    img = image.load_img(image_path, target_size=(224, 224))\n",
    "    array = image.img_to_array(img)\n",
    "    x = np.expand_dims(array, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    fc1 = fc1_model.predict(x)\n",
    "    bg_data_fc1[i] = fc1\n",
    "\n",
    "# save neural codes, labels, paths, and list of classes to pickle file\n",
    "with open(os.path.join(\"data\",\"caltech101_VGG16_fc1.p\"), \"wb\") as f:\n",
    "    pickle.dump((data_fc1, data_labels, data_paths, data_classes), f)\n",
    "\n",
    "# save neural codes & paths of BACKGROUND_Google class to pickle file\n",
    "with open(os.path.join(\"data\",\"caltech101_VGG16_fc1_bg.p\"), \"wb\") as f:\n",
    "    pickle.dump((bg_data_fc1, bg_data_paths), f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
