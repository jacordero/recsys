{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uj4T8PEHGbMF"
   },
   "source": [
    "# Assignment 3\n",
    "## Question 1: Siamese networks & one-shot learning (8pt)\n",
    "The Cifar-100 dataset is similar to the Cifar-10 dataset. It also consists of 60,000 32x32 RGB images, but they are distributed over 100 classes instead of 10. Thus, each class has much less examples, only 500 training images and 100 testing images per class. For more info about the dataset, see https://www.cs.toronto.edu/~kriz/cifar.html.\n",
    "\n",
    "*HINT: Import the Cifar-100 dataset directly from Keras, no need to download it from the website. Use* `label_mode=\"fine\"`\n",
    "\n",
    "### Task 1.1: Siamese network\n",
    "**a)**\n",
    "* Train a Siamese Network on the first 80 classes of (the training set of) Cifar-100, i.e. let the network predict the probability that two input images are from the same class. Use 1 as a target for pairs of images from the same class (positive pairs), and 0 for pairs of images from different classes (negative pairs). Randomly select image pairs from Cifar-100, but make sure you train on as many positive pairs as negative pairs.\n",
    "\n",
    "* Evaluate the performance of the network on 20-way one-shot learning tasks. Do this by generating 250 random tasks and obtain the average accuracy for each evaluation round. Use the remaining 20 classes that were not used for training. The model should perform better than random guessing.\n",
    "\n",
    "For this question you may ignore the test set of Cifar-100; it suffices to use only the training set and split this, using the first 80 classes for training and the remaining 20 classes for one-shot testing.\n",
    "\n",
    "*HINT: First sort the data by their labels (see e.g.* `numpy.argsort()`*), then reshape the data to a shape of* `(n_classes, n_examples, width, height, depth)`*, similar to the Omniglot data in Practical 4. It is then easier to split the data by class, and to sample positive and negative images pairs for training the Siamese network.*\n",
    "\n",
    "*NOTE: do not expect the one-shot accuracy for Cifar-100 to be similar to that accuracy for Omniglot; a lower accuracy can be expected. However, accuracy higher than random guess is certainly achievable.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, Lambda, Dense, Flatten, MaxPooling2D, Dropout, BatchNormalization\n",
    "from keras.models import Model, Sequential\n",
    "from keras.regularizers import l2\n",
    "from keras import backend as K\n",
    "from keras.losses import binary_crossentropy\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_250 (Conv2D)          (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_83 (MaxPooling (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 15, 15, 32)        128       \n",
      "_________________________________________________________________\n",
      "dropout_61 (Dropout)         (None, 15, 15, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_251 (Conv2D)          (None, 14, 14, 64)        8256      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_84 (MaxPooling (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 7, 7, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_62 (Dropout)         (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_252 (Conv2D)          (None, 6, 6, 64)          16448     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_85 (MaxPooling (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "dropout_63 (Dropout)         (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_253 (Conv2D)          (None, 3, 3, 128)         8320      \n",
      "_________________________________________________________________\n",
      "flatten_64 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 1152)              4608      \n",
      "_________________________________________________________________\n",
      "dropout_64 (Dropout)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 128)               147584    \n",
      "=================================================================\n",
      "Total params: 186,752\n",
      "Trainable params: 184,128\n",
      "Non-trainable params: 2,624\n",
      "_________________________________________________________________\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            (None, 32, 32, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_69 (Sequential)      (None, 128)          186752      input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 128)          0           sequential_69[1][0]              \n",
      "                                                                 sequential_69[2][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_133 (Dense)               (None, 1)            129         lambda_2[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 186,881\n",
      "Trainable params: 184,257\n",
      "Non-trainable params: 2,624\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = (32, 32, 3)\n",
    "left_input = Input(input_shape)\n",
    "right_input = Input(input_shape)\n",
    "\n",
    "# build convnet to use in each siamese 'leg'\n",
    "convnet = Sequential()\n",
    "convnet.add(Conv2D(32, (3,3), activation='relu', input_shape=input_shape, kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "convnet.add(Conv2D(64, (2,2), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "convnet.add(Conv2D(64, (2,2), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(MaxPooling2D())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "convnet.add(Conv2D(128, (1,1), activation='relu', kernel_regularizer=l2(2e-4)))\n",
    "convnet.add(Flatten())\n",
    "convnet.add(BatchNormalization())\n",
    "convnet.add(Dropout(0.25))\n",
    "convnet.add(Dense(128, activation=\"sigmoid\", kernel_regularizer=l2(1e-3)))\n",
    "convnet.summary()\n",
    "\n",
    "# encode each of the two inputs into a vector with the convnet\n",
    "encoded_l = convnet(left_input)\n",
    "encoded_r = convnet(right_input)\n",
    "\n",
    "# merge two encoded inputs with the L1 distance between them, and connect to prediction output layer\n",
    "L1_distance = lambda x: K.abs(x[0]-x[1])\n",
    "both = Lambda(L1_distance)([encoded_l, encoded_r])\n",
    "prediction = Dense(1, activation='sigmoid')(both)\n",
    "siamese_net = Model(inputs=[left_input,right_input], outputs=prediction)\n",
    "\n",
    "\n",
    "siamese_net.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
    "\n",
    "siamese_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80, 500, 32, 32, 3)\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 17s 173ms/step - loss: 1.1223\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar100\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "x_train_sorted = x_train[np.argsort(y_train, axis=0)]\n",
    "y_train_sorted = np.sort(y_train, axis=0)\n",
    "\n",
    "x_train_sorted = np.reshape(x_train_sorted, (100, 500, 32, 32, 3))\n",
    "\n",
    "x_train_80, x_train_20 = x_train_sorted[:80], x_train_sorted[80:]\n",
    "y_train_80, y_train_20 = y_train_sorted[:80], y_train_sorted[80:]\n",
    "\n",
    "print(x_train_80.shape)\n",
    "# batch_size = 80\n",
    "# n_examples, width, height, depth = x_train.shape\n",
    "\n",
    "def get_batch(batch_size, X):\n",
    "    \"\"\"Create batch of n pairs, half same class, half different class\"\"\"\n",
    "    n_classes, n_examples, w, h, z = X.shape\n",
    "    # randomly sample several classes to use in the batch\n",
    "    categories = np.random.choice(n_classes, size=(batch_size,), replace=False)\n",
    "    # initialize 2 empty arrays for the input image batch\n",
    "    pairs = [np.zeros((batch_size, h, w, z)) for i in range(2)]\n",
    "    # initialize vector for the targets, and make one half of it '1's, so 2nd half of batch has same class\n",
    "    targets = np.zeros((batch_size,))\n",
    "    targets[batch_size//2:] = 1\n",
    "    for i in range(batch_size):\n",
    "        category = categories[i]\n",
    "        idx_1 = np.random.randint(0, n_examples)\n",
    "        pairs[0][i, :, :, :] = X[category, idx_1].reshape(w, h, z)\n",
    "        idx_2 = np.random.randint(0, n_examples)\n",
    "        # pick images of same class for 1st half, different for 2nd\n",
    "        if i >= batch_size // 2:\n",
    "            category_2 = category\n",
    "        else:\n",
    "            #add a random number to the category modulo n_classes to ensure 2nd image has different category\n",
    "            category_2 = (category + np.random.randint(1,n_classes)) % n_classes\n",
    "        pairs[1][i, :, :, :] = X[category_2,idx_2].reshape(w, h, z)\n",
    "    return pairs, targets\n",
    "\n",
    "def batch_generator(batch_size, X):\n",
    "    \"\"\"a generator for batches, so model.fit_generator can be used. \"\"\"\n",
    "    while True:\n",
    "        pairs, targets = get_batch(batch_size, X)\n",
    "        yield (pairs, targets)\n",
    "\n",
    "def train(model, X_train, batch_size=64, steps_per_epoch=100, epochs=1):\n",
    "    model.fit_generator(batch_generator(batch_size, X_train), steps_per_epoch=steps_per_epoch, epochs=epochs)\n",
    "\n",
    "train(siamese_net, x_train_80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n",
      "Evaluating model on 250 random 20-way one-shot learning tasks ...\n",
      "Got an average of 6.0% accuracy for 20-way one-shot learning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_oneshot_task(N, X, c, language=None):\n",
    "    \"\"\"Create pairs of (test image, support set image) with ground truth, for testing N-way one-shot learning.\"\"\"\n",
    "    n_classes, n_examples, w, h, z = X.shape\n",
    "    indices = np.random.randint(0, n_examples, size=(N,))\n",
    "    if language is not None:\n",
    "        low, high = c[language]\n",
    "        if N > high - low:\n",
    "            raise ValueError(\"This language ({}) has less than {} letters\".format(language, N))\n",
    "        categories = np.random.choice(range(low,high), size=(N,), replace=False)\n",
    "    else:  # if no language specified just pick a bunch of random letters\n",
    "        categories = np.random.choice(range(n_classes), size=(N,), replace=False)            \n",
    "    true_category = categories[0]\n",
    "    ex1, ex2 = np.random.choice(n_examples, replace=False, size=(2,))\n",
    "    test_image = np.asarray([X[true_category, ex1, :, :]]*N).reshape(N, w, h, z)\n",
    "    support_set = X[categories, indices, :, :]\n",
    "    support_set[0, :, :] = X[true_category, ex2]\n",
    "    support_set = support_set.reshape(N, w, h, z)\n",
    "    targets = np.zeros((N,))\n",
    "    targets[0] = 1\n",
    "    targets, test_image, support_set = shuffle(targets, test_image, support_set)\n",
    "    pairs = [test_image, support_set]\n",
    "    return pairs, targets\n",
    "\n",
    "def test_oneshot(model, X, c, N=20, k=250, language=None, verbose=True):\n",
    "    \"\"\"Test average N-way oneshot learning accuracy of a siamese neural net over k one-shot tasks.\"\"\"\n",
    "    n_correct = 0\n",
    "    if verbose:\n",
    "        print(\"Evaluating model on {} random {}-way one-shot learning tasks ...\".format(k, N))\n",
    "    for i in range(k):\n",
    "        inputs, targets = make_oneshot_task(N, X, c, language=language)\n",
    "        probs = model.predict(inputs)\n",
    "        if np.argmax(probs) == np.argmax(targets):\n",
    "            n_correct += 1\n",
    "    percent_correct = (100.0*n_correct / k)\n",
    "    if verbose:\n",
    "        print(\"Got an average of {}% accuracy for {}-way one-shot learning\".format(percent_correct, N))\n",
    "    return percent_correct\n",
    "\n",
    "test_oneshot(siamese_net, x_train_80, y_train_80)\n",
    "test_oneshot(siamese_net, x_train_20, y_train_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MaivGyk_AVTY"
   },
   "source": [
    "***\n",
    "\n",
    "**b)** Briefly motivate your model's architecture, as well as its performance. What accuracy would random guessing achieve (on average)?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lQVd8vHrAYEX"
   },
   "source": [
    "*=== write your answer here ===*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "COiAqXWDAgCe"
   },
   "source": [
    "***\n",
    "\n",
    "**c)** Compare the performance of your Siamese network for Cifar-100 to the Siamese network from Practical 4 for Omniglot. Name three fundamental differences between the Cifar-100 and Omniglot datasets. How do these differences influence the difference in one-shot accuracy?\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IIHkoQ0PBWuB"
   },
   "source": [
    "*=== write your answer here ===*\n",
    "\n",
    "depth = 3 instead of 1\n",
    "\n",
    "Format of images are smaller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VWpFF_5-Bf4B"
   },
   "source": [
    "***\n",
    "\n",
    "### Task 1.2: One-shot learning with neural codes\n",
    "**a)**\n",
    "* Train a CNN classifier on the first 80 classes of Cifar-100. Make sure it achieves at least 40% classification accuracy on those 80 classes (use the test set to validate this accuracy).\n",
    "* Then use neural codes from one of the later hidden layers of the CNN with L2-distance to evaluate one-shot learning accuracy for the remaining 20 classes of Cifar-100. I.e. for a given one-shot task, obtain neural codes for the test image as well as the support set. Then pick the image from the support set that is closest (in L2-distance) to the test image as your one-shot prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_319 (Conv2D)          (None, 30, 30, 6)         168       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_127 (MaxPoolin (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_320 (Conv2D)          (None, 14, 14, 14)        350       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_128 (MaxPoolin (None, 7, 7, 14)          0         \n",
      "_________________________________________________________________\n",
      "flatten_88 (Flatten)         (None, 686)               0         \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 686)               471282    \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 80)                54960     \n",
      "=================================================================\n",
      "Total params: 526,760\n",
      "Trainable params: 526,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/15\n",
      "40000/40000 [==============================] - 20s 507us/step - loss: 5.4215 - acc: 0.0119\n",
      "Epoch 2/15\n",
      "40000/40000 [==============================] - 18s 449us/step - loss: 4.3820 - acc: 0.0122\n",
      "Epoch 3/15\n",
      "40000/40000 [==============================] - 18s 445us/step - loss: 4.3718 - acc: 0.0143\n",
      "Epoch 4/15\n",
      "40000/40000 [==============================] - 18s 455us/step - loss: nan - acc: 0.0171\n",
      "Epoch 5/15\n",
      "40000/40000 [==============================] - 17s 430us/step - loss: nan - acc: 0.0125\n",
      "Epoch 6/15\n",
      "40000/40000 [==============================] - 16s 402us/step - loss: nan - acc: 0.0125\n",
      "Epoch 7/15\n",
      "28416/40000 [====================>.........] - ETA: 5s - loss: nan - acc: 0.0124"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-a14f3586e2f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'rmsprop'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m \u001b[0mcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train_80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m \u001b[0;31m#cnn.evaluate(x_test_80, to_categorical(y_test_80))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar100\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data(label_mode='fine')\n",
    "\n",
    "x_train_sorted = np.reshape(x_train, (50000, 32, 32, 3))\n",
    "x_test_sorted = np.reshape(x_test, (10000, 32, 32, 3))\n",
    "\n",
    "x_train_80, x_train_20 = x_train_sorted[:40000], x_train_sorted[40000:]\n",
    "y_train_80, y_train_20 = y_train_sorted[:40000], y_train_sorted[40000:]\n",
    "\n",
    "x_test_80, x_test_20 = x_test_sorted[:8000], x_test_sorted[8000:]\n",
    "y_test_80, y_test_20 = y_test_sorted[:8000], y_test_sorted[8000:]\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(6, (3, 3), input_shape=(32, 32, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Conv2D(14, (2, 2), activation='relu'))\n",
    "cnn.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "cnn.add(Flatten())\n",
    "\n",
    "cnn.add(Dense(686, activation='relu'))\n",
    "cnn.add(Dense(80, activation='sigmoid'))\n",
    "cnn.summary()\n",
    "\n",
    "cnn.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "cnn.fit(x_train_80, to_categorical(y_train_80), epochs=15, batch_size=64)\n",
    "#cnn.evaluate(x_test_80, to_categorical(y_test_80))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M1BDzdPAz26B"
   },
   "source": [
    "***\n",
    "\n",
    "**b)** Briefly motivate your CNN architecture, and discuss the difference in one-shot accuracy between the Siamese network approach and the CNN neural codes approach.\n",
    "\n",
    "**Answer:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oRpVm956FR8P"
   },
   "source": [
    "*=== write your answer here ===*"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Assignment 3 question 1.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
